[["index.html", "The Bacterial Genomics Book Chapter 1 Learning the basics 1.1 The Command Line 1.2 R 1.3 Python 1.4 Interactive tools", " The Bacterial Genomics Book Amber Barton 2025-10-19 Chapter 1 Learning the basics 1.1 The Command Line Many bacterial genomics tools, particularly those working directly with fastq files, have no graphical interfaces and therefore require you to use the command line. Many universities and research institutes will have a high performance compute (HPC) facility, and their own guidelines on how to access and use it. Alternatively, it is possible to run many of these tools on a Mac by opening the Terminal app. If you have a windows computer and no access to a HPC, you will need to install linux, e.g. using WSL. If you are unfamiliar with the command line it will take some time to get used to- particularly navigating and moving files, and running loops. I used the following courses to get started: Codecademy Learn the command line Coursera Command Line Tools for Genomic Data Science 1.2 R Downstream genomics analysis and data visualisation is often carried out using R. Unlike the command line, R can be easily run on either a Mac or a Windows computer. Download R I would also strongly recommend downloading R studio, which makes it easy to write reproducible scripts (File &gt; New File &gt; R Script), view the files in your environment and plot graphs. Download RStudio To learn R, I would recommend you start with the interactive R Programming course provided as part of the Swirl package. For data visualisation, the ggplot2 cheat sheet and R graph gallery are both brilliant resources. 1.3 Python While this book with primarily focus on R, some prefer Python for data analysis, as it is more versatile, and relevant for those looking to pursue careers in industry or data science. Resources for learning Python include ROSALIND, Codecademy and Coursera. 1.4 Interactive tools It is possible to carry out small-scale analyses using interactive websites and tools. Many tools that would usually be run on the command line can be carried out using Galaxy, and genome assembly, lineage assignment and antimicrobial resistance prediction can be carried out using PathogenWatch. BLAST is extremely useful for checking whether your query sequence matches anything in NCBI’s databases, or whether two sequences have local similarity. "],["publicly-available-datasets.html", "Chapter 2 Publicly available datasets 2.1 Downloading fastq files from a published study 2.2 Downloading fastq files from a systematic search or multi-study collection 2.3 Downloading assemblies from online databases", " Chapter 2 Publicly available datasets 2.1 Downloading fastq files from a published study For sequencing papers, often a Study Accession (e.g. PRJEB8764) will be provided in the methods, and sample or run accessions (e.g. ERR1880809) in the supplementary documents. One of the easiest ways of downloading fastq files is to visit the ENA website, type in an accession, and click “download”. If you click “download all”, you will be given a script you can run in the command line to download the files at scale. 2.2 Downloading fastq files from a systematic search or multi-study collection Go on to NCBI SRA and type in your search. For example, if I wanted to find Shigella (taxonomic ID 624) DNA whole-genome sequences from India, I might type in: txid624[Organism] AND “WGS”[Strategy] AND “biomol dna”[Properties] AND “India”[Country] You can then click “Send results to Run selector”, which will give you a neatly formatted table with a list of the run accessions and metadata. Once you have a list of run accessions, you can download the fastq files using SRA toolkit. #Downloads runs in SRA format prefetch --option-file SraAccList.txt #Loop through the downloaded files to convert to fastq for i in *RR* do fasterq-dump --split-files $i done #Compress to get fastq.gz files gzip *fastq Alternatively, the following R function, which uses the readR and httr packages, can be used to retrieve the url of a fastq.gz file when given a run accession. library(httr) library(readr) get_fastq_urls &lt;- function(accession) { res &lt;- GET(&quot;https://www.ebi.ac.uk/ena/portal/api/filereport&quot;, query = list(accession = accession, result = &quot;read_run&quot;, fields = &quot;fastq_ftp&quot;, format = &quot;tsv&quot;)) df &lt;- read_tsv(content(res, &quot;text&quot;, encoding = &quot;UTF-8&quot;), show_col_types = FALSE) if (nrow(df) == 0 || !&quot;fastq_ftp&quot; %in% names(df) || is.na(df$fastq_ftp) || df$fastq_ftp == &quot;&quot;) return(warning(sprintf(&quot;No FASTQ found for %s&quot;, accession))) paste0(&quot;https://&quot;, unlist(strsplit(as.character(df$fastq_ftp), &quot;;&quot;)))} get_fastq_urls(&quot;ERR1880809&quot;) ## Warning in get_fastq_urls(&quot;ERR1880809&quot;): No FASTQ found for ERR1880809 You can then download them using the wget function in the command line. wget https://ftp.sra.ebi.ac.uk/vol1/fastq/ERR188/009/ERR1880809/ERR1880809_1.fastq.gz wget https://ftp.sra.ebi.ac.uk/vol1/fastq/ERR188/009/ERR1880809/ERR1880809_2.fastq.gz 2.3 Downloading assemblies from online databases Enterobase and Pathogenwatch are both good resources for downloading ready-made assemblies for certain pathogens, particularly enteric pathogens. For a more comprehensive search, you could visit NCBI Genome. Currently, if I type in “Vibrio cholerae”, NCBI genome will return 14,025 genomes. If I click filter I can then filter by assembly level, for example “chromosome” (516 genomes) or “complete” (474 genomes). These genomes can be downloaded using ncbi-datasets-cli. #Download all complete Vibrio cholerae assemblies datasets download genome taxon 666 --assembly-level complete --filename Cholera.zip --include genome #Download a particular assembly for which you have an accession datasets download genome accession GCA_003574155.1 --filename V060002.zip --include genome "],["running-commands-on-many-samples.html", "Chapter 3 Running commands on many samples 3.1 For loops 3.2 While loops 3.3 Write a script", " Chapter 3 Running commands on many samples 3.1 For loops When you are working with a large number of fastq files or assemblies, for and while loops are extremely useful. Below is an example of how you might use a for loop to work on paired fastq files. In this example we are simply concatenating the files, but you could adapt this for any command where you need to provide paired fastq files. for i in *_1.fastq.gz do #Create an ID without &quot;_1.fastq.gz&quot; at the end id=$(basename $i | sed &#39;s/_1.fastq.gz//g&#39;) #Check both files are present ls ${id}_1.fastq.gz ls ${id}_2.fastq.gz #Concatenate cat ${id}_1.fastq.gz ${id}_2.fastq.gz &gt; ${id}.fastq.gz done 3.2 While loops Alternatively, you might have a tab-delimited file which contains the ID, the path to fastq file 1, and the path to fastq file 2. A file in this format is needed to run snippy-multi for a reference based alignment. ERR976479 ERR976479_1.fastq.gz ERR976479_2.fastq.gz ERR351174 ERR351174_1.fastq.gz ERR351174_2.fastq.gz ERR576974 ERR576974_1.fastq.gz ERR576974_2.fastq.gz ERR11850183 ERR11850183_1.fastq.gz ERR11850183_2.fastq.gz A while loop can be used to achieve something similar to above: cat filelocations.txt | while read line do echo $line id=$(echo &quot;$line&quot; | awk &#39;{print $1}&#39;) fastq1=$(echo &quot;$line&quot; | awk &#39;{print $2}&#39;) fastq2=$(echo &quot;$line&quot; | awk &#39;{print $3}&#39;) #Check both files are present ls $fastq1 ls $fastq2 #Concatenate cat $fastq1 $fastq1 &gt; ${id}.fastq.gz done For simplicity, in the rest of the book I have not included loops, even though for many of these commands you would most likely be using them. 3.3 Write a script If you really want to avoid using loops, another way is to use excel or R to write a script. Say, as above, you have a tab delimited file with your IDs and paths to your fastq files. ERR976479 ERR976479_1.fastq.gz ERR976479_2.fastq.gz ERR351174 ERR351174_1.fastq.gz ERR351174_2.fastq.gz ERR576974 ERR576974_1.fastq.gz ERR576974_2.fastq.gz ERR11850183 ERR11850183_1.fastq.gz ERR11850183_2.fastq.gz Using excel, you could create a file that looks like this: cat ERR976479_1.fastq.gz ERR976479_2.fastq.gz &gt; ERR976479.fastq.gz cat ERR351174_1.fastq.gz ERR351174_2.fastq.gz &gt; ERR351174.fastq.gz cat ERR576974_1.fastq.gz ERR576974_2.fastq.gz &gt; ERR576974.fastq.gz cat ERR11850183_1.fastq.gz ERR11850183_2.fastq.gz &gt; ERR11850183.fastq.gz Save this as a csv, then open it using Notepad or Textedit. Find and replace all commas with a space. cat ERR976479_1.fastq.gz ERR976479_2.fastq.gz &gt; ERR976479.fastq.gz cat ERR351174_1.fastq.gz ERR351174_2.fastq.gz &gt; ERR351174.fastq.gz cat ERR576974_1.fastq.gz ERR576974_2.fastq.gz &gt; ERR576974.fastq.gz cat ERR11850183_1.fastq.gz ERR11850183_2.fastq.gz &gt; ERR11850183.fastq.gz Now save this as a file with the extension “.sh”. Use the chmod command to make the file executable, then run it is a bash script. chmod 777 *sh ./my_new_script.sh "],["fastq-quality-control.html", "Chapter 4 Fastq quality control 4.1 FastQC and MultiQC 4.2 Trimming reads 4.3 Contamination", " Chapter 4 Fastq quality control 4.1 FastQC and MultiQC Fastq quality control can be carried out using FastQC. #Run on all fastq files in a directory fastqc *fastq.gz MultiQC can then be used to create a) An html report, and b) A folder multiqc_data #Run on all fastq files in a directory multiqc . Based on the contents of multiqc_data/multiqc_fastqc.txt, you may choose to exclude poor quality fastq files. 4.2 Trimming reads If you don’t want to exclude samples, but have reads that drop in quality towards the 3’ end, you may wish to trim your reads to improve the quality (although it is debated whether or not this is necessary). One tool for this is fastp to trim or remove poor quality reads. fastp -i ERR11850183_1.fastq.gz -I ERR11850183_2.fastq.gz -o ERR11850183_trimmed_1.fastq.gz -O ERR11850183_trimmed_2.fastq.gz --cut_front --cut_tail 4.3 Contamination Even for whole-genome sequencing it is possible you will have contamination, or isolated the wrong species. You can check for this using a metagenome profiler such as kraken2 or sylph. db=Directory/containing/kraken/database kraken2 --db $db --paired ERR11850183_1.fastq.gz ERR11850183_2.fastq.gz --gzip-compressed --output /dev/null --report ERR11850183_krakenreport "],["genome-assembly.html", "Chapter 5 Genome assembly 5.1 Short-read 5.2 Hybrid and long-read 5.3 Quality control 5.4 Annotation", " Chapter 5 Genome assembly 5.1 Short-read Illumina sequencing data can be assembled using SPAdes. #Paired end reads spades.py -1 ERR11850183_1.fastq.gz -2 ERR11850183_2.fastq.gz -o ERR11850183_assembly #Single end reads spades.py -s ERR11850183.fastq.gz -o ERR11850183_assembly #Metagenomic assembly (paired reads only) metaspades.py -1 ERR11850183_1.fastq.gz -2 ERR11850183_2.fastq.gz -o ERR11850183_assembly The output scaffolds.fasta can then be used for further analyses. I would recommend moving and renaming this file. mv ERR11850183_assembly/scaffolds.fasta ERR11850183.fasta 5.2 Hybrid and long-read Unicycler can be used for long-read and hybrid assemblies. #Hybrid assembly unicycler -1 short_reads_1.fastq.gz -2 short_reads_2.fastq.gz -l long_reads.fastq.gz -o output_dir 5.3 Quality control CheckM2 can be used to estimate the completeness and contamination of an assembly. By default, CheckM2 assumes that assemblies end with the extension “fasta”. checkm2 predict --input folder_containing_assemblies --output-directory output_folder QUAST, an alternative tool, can also be used for assembly quality control using a reference genome for comparison. reference=/path/to/reference/genome #Assuming we are in a working directory containing assemblies with the file extension &quot;fasta&quot; quast.py *fasta -R $reference 5.4 Annotation Prokka is a fast method of genome annotation that is compatible with downstream pangenome analyses using panaroo. prokka genome.fasta -o output_folder_name You will then get a folder output_folder_name containing a number of files, including a gff file. I would recommend moving and renaming this file. prokka ERR11850183.fasta -o ERR11850183_annotation mv ERR11850183_annotation/*gff ERR11850183.gff "],["alignments.html", "Chapter 6 Alignments 6.1 Reference-based alignments 6.2 Checking coverage 6.3 Sub-setting an alignment 6.4 Detecting recombination 6.5 Masking regions 6.6 Core gene alignments 6.7 SNP alignment 6.8 VCF conversion", " Chapter 6 Alignments 6.1 Reference-based alignments If you are studying a pathogen with low genetic variation you might prefer to do a reference-based alignment rather than a core-gene alignment. The advantage of this is you can work directly with reads rather than having to build assemblies. Snippy is an easy tool to achieve this. The easiest way to do this, particularly if you have hundreds rather than thousands of samples, is to create a tab-delimited file with your IDs and the paths to your fastq files, and run snippy-multi. ERR976479 ERR976479_1.fastq.gz ERR976479_2.fastq.gz ERR351174 ERR351174_1.fastq.gz ERR351174_2.fastq.gz ERR576974 ERR576974_1.fastq.gz ERR576974_2.fastq.gz ERR11850183 ERR11850183_1.fastq.gz ERR11850183_2.fastq.gz ref=path/to/reference.fasta snippy-multi input.tab --ref $ref &gt; snippyscript.sh #Make it executable chmod 777 snippyscript.sh #Run the script ./snippyscript.sh If you have many samples it will take a long time for this script to run. In this case you might want to run snippy on individual samples first using loops then create a reference based alignment. ref=path/to/reference.fasta #Run snippy for individual samples, e.g. using a for loop snippy --outdir ERR11850183 --ref $ref --R1 ERR11850183_1.fastq.gz --R2 ERR11850183_2.fastq.gz snippy --outdir ERR976479 --ref $ref --R1 ERR976479_1.fastq.gz --R2 ERR976479_2.fastq.gz #Create the alignment snippy-core --prefix core ERR11850183 ERR976479 6.2 Checking coverage You can check the proportion of low coverage (“N”) and zero coverage “-” bases using the Biostrings package in R. library(Biostrings) #Read in alignment alignment = readDNAStringSet(&quot;alignment.aln&quot;) #Calculate frequency of each base frequency = as.data.frame(alphabetFrequency(alignment)) rownames(frequency) = names(alignment) #Calculate the percentage of N and - for each sample frequency$Percent_missing = 100*(frequency$N + frequency$`-`)/rowSums(frequency) #Which samples have over 50% missing? rownames(frequency[which(frequency$Percent_missing &gt; 50),]) #Write the names of good quality samples to a file good_quality = rownames(frequency[which(frequency$Percent_missing &lt; 50),]) cat(good_quality, sep = &quot;\\n&quot;, file = &quot;good_quality_alignment.txt&quot;) 6.3 Sub-setting an alignment There are many cases where you may want to subset an alignment- for example, to exclude samples that are poor quality, or that are very distant from other samples. In addition to your alignment, you need a text file containing a list of samples you want to keep- one per line, e.g. good_quality_alignment.txt created in Check coverage. seqtk subseq alignment.aln good_quality_alignment.txt &gt; goodquality.aln 6.4 Detecting recombination If you create a tree at this point it may be biased by recombination. Gubbins can detect recombinogenic regions in a reference-based alignment and exclude them. run_gubbins.py alignment.aln This will give you a .gff file which contains the start and end of each recombination region. 6.5 Masking regions Having detected recombination, masking is useful to remove these regions before building a tree. You can use the following commands to convert this to a .bed file, and mask these regions of the genome using bedtools. #Get co-ordinates from gff file awk -v OFS=&quot;\\t&quot; &#39;{ if($0 !~ /^#/){ print $4, $5 } }&#39; recombination_predictions.gff &gt; coords.txt #Extract sequence names from alignment grep &quot;^&gt;&quot; alignment.aln | sed &#39;s/^&gt;//&#39; &gt; names.txt #Create a bed file with every recombinogenic region for every sequence awk -v OFS=&quot;\\t&quot; &#39;NR==FNR {names[NR]=$0; n=NR; next} {for (i=1;i&lt;=n;i++) print names[i], $1, $2}&#39; names.txt coords.txt &gt; recombination.bed #Mask the alignment bedtools maskfasta -fi alignment.aln -bed recombination.bed -fo masked_alignment.aln This will replace the recombinogenic region with “N”. You can double check this using the method outlined in Checking coverage. 6.6 Core gene alignments If you have created assemblies and annotated them you can create a core gene alignment using panaroo. The advantage of this over reference-based alignment is you don’t need an extra step to account for recombination, and the output of panaroo is also useful for gene presence/absence, identifying mobile genetic elements, and genome wide association. It can also be used for analysing datasets with high levels of diversity. The disadvantage is you need to be careful to make sure that the samples share enough genes- this means you must exclude assemblies with very low completeness. If you have all your gff files in one folder, panaroo is extremely easy to run: panaroo -i *gff -o panaroo_core --clean-mode strict --alignment core This will create the alignment files core_gene_alignment.aln and core_gene_alignment_filtered.aln within the folder panaroo_core. 6.7 SNP alignment The whole-genome alignment files generated in Reference-based alignments and Core gene alignments can be very large and difficult to work with. Snp-sites can be used to work out which regions are constant (you will need this for IQTree) and extract SNPs. #Create SNP-only alignment snp-sites alignment.aln -o snps.aln #How many sites were constant? snp-sites -Cb alignment.aln -o constant 6.8 VCF conversion Snp-sites is also very useful if you need to convert an alignment to VCF format for downstream analysis. snp-sites alignment.aln -v -o snps.vcf "],["building-trees.html", "Chapter 7 Building trees 7.1 FastTree 7.2 IQ-TREE", " Chapter 7 Building trees 7.1 FastTree Once you have created your SNP alignment you can create a tree. FastTree is a good option for creating a approximately-maximum-likelihood phylogenetic tree quickly. FastTree -gtr -nt snps.aln &gt; fast.tree 7.2 IQ-TREE IQ-TREE takes longer and uses more memory, but creates a maximum-likelihood phylogenetic tree. Another advantage of IQ-tree is you can input the number of constant sites (see SNP alignment). #If you have the file &quot;constant&quot; from the SNP alignment section, you can assign it to a variable and input it into IQ-tree CONSTANTS=$(cat constant) #Run IQ-tree- here using a HKY+F+I model iqtree -s snps.aln -m HKY+F+I -fconst $CONSTANTS Note that IQ-TREE will change all “#” in file names to “_“, and will give a tree with the extenstion”treefile”. "],["rooting-trees.html", "Chapter 8 Rooting trees 8.1 Outgroup 8.2 Midpoint 8.3 Molecular clock", " Chapter 8 Rooting trees While an unrooted tree shows relationships between samples, it does not indicate the directionality of evolutionary change. There are several methods of rooting trees. 8.1 Outgroup Include a sample that is more evolutionarily divergent from the rest of the samples- e.g. if you are focusing on one sub-species, include an out-group that belongs to the same species, but different sub-species. 8.2 Midpoint Midpoint rooting places the root half-way between the longest tips. This can be performed using the ape and phytools packages in R. library(ape) library(phytools) tree = read.tree(&quot;fast.tree&quot;) tree = midpoint.root(tree) 8.3 Molecular clock This method finds the root most consistent with the sampling dates of the sequences. This is the method used by BEAST and BEAST2. However here we demonstrate two quicker methods of generating a time-scaled phylogeny. 8.3.1 TreeTime Treetime is a command line tool that can also be used to estimate a time-scaled phylogeny. In this case you will need your tree, your alignment, and your metadata in csv format. treetime --tree fast.tree --dates metadata.csv --outdir treetime_results --date-column date --name-column ID --aln snps.aln 8.3.2 BactDating The R package BactDating can also reroot a tree. library(ape) library(BactDating) tree = read.tree(&quot;fast.tree&quot;) You will need a data frame containing the dates. You can use the lubridate package to convert dates in YYYY-MM-DD format to decimal dates. library(lubridate) metadata$decimaldate = decimal_date(df$date) ID date decimaldate Group1 Group2 sample_1 1990-01-01 1990 C E sample_2 1991-01-01 1991 A E sample_3 1992-01-01 1992 C F sample_4 1993-01-01 1993 A E sample_5 1994-01-01 1994 B F sample_6 1995-01-01 1995 C F dates = metadata$decimaldate names(dates) = metadata$ID dates ## sample_1 sample_2 sample_3 sample_4 sample_5 sample_6 sample_7 sample_8 sample_9 sample_10 ## 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 ## sample_11 sample_12 sample_13 sample_14 sample_15 sample_16 sample_17 sample_18 sample_19 sample_20 ## 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 ## sample_21 ## 2010 roottotip(tree,dates) ## $rate ## date ## 9.162776 ## ## $ori ## (Intercept) ## 1962.519 ## ## $pvalue ## [1] 0 results = bactdate(tree,dates) rooted_tree = results$tree "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
